
# USP S√£o Carlos ‚Äì Pipeline Automatizado de Indicadores Institucionais
[üá∫üá∏ English](README_EN.md) | Portugu√™s

![USP S√£o Carlos](https://img.shields.io/badge/USP-S√£o%20Carlos-0050A0)
![Projeto Institucional](https://img.shields.io/badge/Projeto-Institucional-blue)
![PUB-USP](https://img.shields.io/badge/PUB-USP%202024/2025-lightgrey)
![ETL](https://img.shields.io/badge/ETL-Produtivo-success)
![Valida√ß√£o](https://img.shields.io/badge/Valida√ß√£o-2019--2024-green)
![Reutiliz√°vel](https://img.shields.io/badge/Reutiliz√°vel-Anualmente-important)
![Licen√ßa](https://img.shields.io/badge/Licen√ßa-MIT-black)


Este reposit√≥rio cont√©m um pipeline completo para automa√ß√£o da coleta, filtragem e padroniza√ß√£o dos principais indicadores do campus da USP S√£o Carlos, extra√≠dos diretamente do Anu√°rio Estat√≠stico da USP (USP Digital).

O projeto foi desenvolvido no √¢mbito do Programa Unificado de Bolsas (PUB-USP) com o objetivo de substituir o processo manual de obten√ß√£o de dados institucionais por uma solu√ß√£o reproduz√≠vel, padronizada e facilmente reutiliz√°vel em edi√ß√µes futuras do Anu√°rio.

---

## Problema que o projeto resolve

O Anu√°rio apresenta dados consolidados para toda a USP, o que obriga cada campus a realizar uma coleta manual para obter seus pr√≥prios indicadores.
Esse processo √© lento, suscet√≠vel a erros, inconsistente entre anos e precisa ser refeito a cada nova edi√ß√£o.

Este pipeline elimina esse problema ao:

- realizar a extra√ß√£o direta das tabelas oficiais via HTTP;
- padronizar automaticamente colunas e formatos que variam entre edi√ß√µes;
- filtrar exclusivamente os dados referentes ao campus S√£o Carlos;
- gerar arquivos finais prontos para an√°lise em CSV;
- permitir a repeti√ß√£o anual do processo com esfor√ßo praticamente nulo.

---

## Avan√ßo em rela√ß√£o ao cronograma oficial

De acordo com o cronograma previsto no edital do PUB-USP, o projeto est√° dividido em etapas distribu√≠das ao longo de 12 meses, incluindo estudo das tabelas, desenvolvimento gradual dos m√≥dulos, testes, documenta√ß√£o e treinamento.

A execu√ß√£o real iniciou-se em **04 de setembro**.  
Em menos de 3 meses trabalho, j√° foram conclu√≠dos:

- o m√≥dulo completo de extra√ß√£o;
- o m√≥dulo completo de transforma√ß√£o;
- o m√≥dulo de carga;
- o pipeline integrado, testado e validado com as edi√ß√µes de 2019 a 2024;
- a filtragem e padroniza√ß√£o do campus S√£o Carlos;
- a estrutura final de ETL (Extract, Transform, Load) em formato reutiliz√°vel.

O pipeline √© totalmente gen√©rico e independente do ano; as edi√ß√µes 2019‚Äì2024 foram utilizadas apenas para valida√ß√£o. O sistema est√° preparado para processar automaticamente quaisquer futuros Anu√°rios, assim que forem publicados.

Conclus√£o: O motor de ETL est√° operacional 4 meses antes do previsto no cronograma oficial.

---

## Tech Stack
* **Linguagem:** Python
* **Manipula√ß√£o de Dados:** Pandas (DataFrames, Pivot Tables, Cleaning)
* **Ingest√£o de Dados:** Requests (Web Scraping de arquivos est√°ticos)
* **Compatibilidade Excel:** OpenPyXL, xlrd

---
## Arquitetura do projeto

etl/
‚îÇ‚îÄ‚îÄ extract.py        # Download das tabelas diretamente do USP Digital
‚îÇ‚îÄ‚îÄ transform.py      # Padroniza√ß√£o de colunas e filtragem de S√£o Carlos
‚îÇ‚îÄ‚îÄ load.py           # Salvamento dos resultados em CSV
‚îî‚îÄ‚îÄ pipeline.py       # Orquestra√ß√£o completa do processo

data/
‚îÇ‚îÄ‚îÄ raw/              # (opcional) tabelas brutas, caso queira armazenar
‚îî‚îÄ‚îÄ processed/        # CSVs finais prontos para an√°lise

notebooks/
‚îî‚îÄ‚îÄ usp_sao_carlos_data_pipeline.ipynb   # Notebook original usado no prot√≥tipo

docs/
‚îî‚îÄ‚îÄ PUB-Projeto.pdf   # Documento oficial com o cronograma e descri√ß√£o do projeto

requirements.txt
README.md

## Sobre a pasta `data/raw`

A pasta `data/raw` representa o local reservado para armazenar arquivos brutos baixados do Anu√°rio, antes de qualquer filtragem ou transforma√ß√£o.  
Ela faz parte da arquitetura padr√£o de projetos de engenharia de dados, especialmente quando h√° interesse em hist√≥rico, auditoria ou reprocessamento.

No entanto, como os arquivos brutos podem ser grandes e variam a cada edi√ß√£o do Anu√°rio, a pasta permanece **vazia no GitHub**.  
Isso evita que o reposit√≥rio se torne pesado e garante que apenas o c√≥digo essencial permane√ßa versionado.

Localmente, o uso dessa pasta √© opcional. Ela pode ser utilizada para:
- armazenar as tabelas originais (`.xls` ou `.csv`) baixadas do USP Digital;  
- manter hist√≥rico de dados para valida√ß√£o ou auditoria;  
- evitar downloads repetidos durante o desenvolvimento;  
- permitir reprocessamento offline.
